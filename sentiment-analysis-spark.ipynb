{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyst -  Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cahier, nous utiliserons le framework Spark pour construire un modèle d'analyse des sentiments basé sur l'algorithme Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble de données est un avis de plusieurs utilisateurs sur le bot Amazon Alexa, où chaque ligne a un `review` et un `rating` (de 1 à 5 étoiles) et d'autres colonnes.  \n",
    "Lien pour télécharger les données: [Data Source](https://www.kaggle.com/sid321axn/amazon-alexa-reviews#amazon_alexa.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, udf\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer, \\\n",
    "    IDF, StopWordsRemover, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Sentiment Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/amazon-alexa-reviews.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"sep\", \"\\t\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------------+--------------------+--------+\n",
      "|rating|     date|       variation|    verified_reviews|feedback|\n",
      "+------+---------+----------------+--------------------+--------+\n",
      "|     5|31-Jul-18|Charcoal Fabric |       Love my Echo!|       1|\n",
      "|     5|31-Jul-18|Charcoal Fabric |           Loved it!|       1|\n",
      "|     4|31-Jul-18|  Walnut Finish |Sometimes while p...|       1|\n",
      "+------+---------+----------------+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui nous intéresse sont les deux colonnes `rating` et `verified_reviews`.  Donc nous allons vérifier si ces deux colonnes contient déja des valeurs null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   object\n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.toPandas().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto! aucune valeur null.  \n",
    "Pour comparer le nombre des `rating`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|rating|count(rating)|\n",
      "+------+-------------+\n",
      "|     1|          161|\n",
      "|     2|           96|\n",
      "|     3|          152|\n",
      "|     4|          455|\n",
      "|     5|         2286|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('rating').agg(count('rating')).orderBy('rating').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les rating du 5 étoiles domine le dataset.  \n",
    "Maintenant nous pouvons nous débarrasser des colonnes inutiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons créer les 2 classes des sentiment:\n",
    "0. => Sentiment Négatif (1-3 étoiles)\n",
    "1. => Sentiment Positif (4-5 étoiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------------+----------------+--------+------+\n",
      "|rating|     date|       variation|verified_reviews|feedback|classe|\n",
      "+------+---------+----------------+----------------+--------+------+\n",
      "|     5|31-Jul-18|Charcoal Fabric |   Love my Echo!|       1|     1|\n",
      "+------+---------+----------------+----------------+--------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_col = udf(lambda x: int((x =='5')|(x=='4')), IntegerType())  \n",
    "df = df.withColumn('classe', label_col(df.rating))\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = df.drop(*['date', 'variation', 'feedback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+\n",
      "|rating|    verified_reviews|classe|\n",
      "+------+--------------------+------+\n",
      "|     5|       Love my Echo!|     1|\n",
      "|     5|           Loved it!|     1|\n",
      "|     4|Sometimes while p...|     1|\n",
      "+------+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfn.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraction des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons extraire les features nécessaires pour l'apprentisage de notre model à partir de la colonne `verified_reviews`.  \n",
    "Mais avant ça nous allons préparer nos données, en supprimant les tags HTML, les mots vides (et, dans ..), déplacer les emojis à la fin du texte, et transformer le texte en miniscule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', str(text))\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_udf = udf(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = dfn.withColumn('prepared_reviews', preprocessor_udf(col('verified_reviews')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+--------------------+\n",
      "|rating|    verified_reviews|classe|    prepared_reviews|\n",
      "+------+--------------------+------+--------------------+\n",
      "|     5|       Love my Echo!|     1|       love my echo |\n",
      "|     5|           Loved it!|     1|           loved it |\n",
      "|     4|Sometimes while p...|     1|sometimes while p...|\n",
      "+------+--------------------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfn.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diviser le texte en mots séparés\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"prepared_reviews\", outputCol=\"mots\", pattern=\"\\\\W\")\n",
    "dfn = regexTokenizer.transform(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------+----------------+----------------+\n",
      "|rating|verified_reviews|classe|prepared_reviews|            mots|\n",
      "+------+----------------+------+----------------+----------------+\n",
      "|     5|   Love my Echo!|     1|   love my echo |[love, my, echo]|\n",
      "+------+----------------+------+----------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfn.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer les mots vides\n",
    "remover = StopWordsRemover(inputCol='mots', outputCol='mots_clean')\n",
    "dfn = remover.transform(dfn).select('rating', 'mots_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|rating|  mots_clean|\n",
      "+------+------------+\n",
      "|     5|[love, echo]|\n",
      "|     5|     [loved]|\n",
      "+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfn.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rating='5', mots_clean=['love', 'echo'], TF=SparseVector(3947, {0: 1.0, 1: 1.0}))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trouver le terme fréquences des mots\n",
    "cv = CountVectorizer(inputCol=\"mots_clean\", outputCol=\"TF\")\n",
    "cvmodel = cv.fit(dfn)\n",
    "dfn = cvmodel.transform(dfn)\n",
    "dfn.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(rating='5', mots_clean=['love', 'echo'], TF=SparseVector(3947, {0: 1.0, 1: 1.0}), TFIDF=SparseVector(3947, {0: 1.334, 1: 1.6652}), features=SparseVector(3947, {0: 1.334, 1: 1.6652}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trouver le Inter-document Frequency\n",
    "idf = IDF(inputCol=\"TF\", outputCol=\"features\")\n",
    "idfModel = idf.fit(dfn)\n",
    "dfn = idfModel.transform(dfn)\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer la colonne d'étiquette\n",
    "indexer = StringIndexer(inputCol=\"classe\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Créer le ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprés définir tout les fonctions nécaissaires pour traiter notre dataset, nous allons les enchainer dans un pipeline pour construire notre modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(*['date', 'variation', 'feedback'])\n",
    "data = data.withColumn('prepared_reviews', preprocessor_udf(col('verified_reviews')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisez le jeu de données au hasard en ensembles de formation et de test\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer le pipeline\n",
    "nb = NaiveBayes(smoothing=1.0)\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, cv, idf, indexer, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éxecuter les étapes du pipeline et former le modele\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions sur testData \n",
    "#afin que nous puissions mesurer la précision de notre modèle sur de nouvelles données\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer notre modele nous allons utiliser `Evaluator` de `MulticlassClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "            metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.8923240938166311\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon, une précision de `90%` sur ce simple dataset n'est pas mauvais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
